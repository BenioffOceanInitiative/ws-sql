---
title: "load_rgns"
author: "Ben Best"
date: "9/2/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
librarian::shelf(
  dplyr, glue, here, lwgeom, purrr, sf, stringr, tibble)
source(here("scripts/db.R"))
```


## Create Regions

Sources:
* [Marine Regions · United States Exclusive Economic Zone (EEZ)](https://www.marineregions.org/gazetteer.php?p=details&id=8456)
* [Marine Regions · Gulf of Saint Lawrence (IHO Sea Area)](https://www.marineregions.org/gazetteer.php?p=details&id=4290)

```{r}
# got these urls by visiting these places on marineregions.org, then Download as JSON
usa_url <- "https://geo.vliz.be/geoserver/wfs?request=getfeature&service=wfs&version=1.1.0&typename=MarineRegions:eez&outputformat=json&filter=%3CPropertyIsEqualTo%3E%3CPropertyName%3Emrgid%3C%2FPropertyName%3E%3CLiteral%3E8456%3C%2FLiteral%3E%3C%2FPropertyIsEqualTo%3E"

can_gsl_url <- "https://geo.vliz.be/geoserver/wfs?request=getfeature&service=wfs&version=1.1.0&typename=MarineRegions:iho&outputformat=json&filter=%3CPropertyIsEqualTo%3E%3CPropertyName%3Eid%3C%2FPropertyName%3E%3CLiteral%3E24%3C%2FLiteral%3E%3C%2FPropertyIsEqualTo%3E"

usa_json     <- here("data/usa_parts.geojson")
fl_json      <- here("data/fl_line.geojson") # manually created in QGIS
rgns_json    <- here("data/ws-rgns.geojson")

if (!file.exists(rgns_json)){
  
  if (!file.exists(usa_json)){
    usa <- sf::read_sf(usa_url)
    
    usa_parts <- st_cast(usa, "POLYGON") %>% 
      rownames_to_column("rowid") %>% 
      select(rowid, geometry) %>% 
      st_as_sf(sf_column_name = "geometry")
    
    write_sf(usa_parts, usa_json)
  }
  
  usa_parts <- read_sf(usa_json)
  fl_ln     <- read_sf(fl_json)

  # split
  rgns <- lwgeom::st_split(usa_parts, fl_ln) %>% # SLOW: 15 minutes
    st_collection_extract(c("POLYGON"))
  
  # add ctr_lon to differentiate
  rgns <- rgns %>% 
    mutate(
      pt_ctr = st_centroid(geometry),
      ctr_lon = map_dbl(pt_ctr, ~ st_coordinates(.x)[1]),
      ctr_lat = map_dbl(pt_ctr, ~ st_coordinates(.x)[2])) %>% 
    select(-pt_ctr) %>% 
    arrange(rowid, ctr_lon) %>% 
    rownames_to_column("rowid2")
  
  rgns <- rgns %>% 
    filter(ctr_lon < -80.5) %>% 
    arrange(ctr_lon) %>% 
    mutate(
      region = c("USA-West", "USA-GoMex")) %>% 
    select(region, geometry) %>% 
    rbind(
      # East
      rgns %>% 
        # st_drop_geometry() %>% 
        filter(ctr_lon > -80.5) %>% 
        st_union()  %>% 
        st_as_sf() %>% 
        mutate(
          region = "USA-East") %>% 
        rename(geometry = x))

  # + Canada's Gulf of St Lawrence
  # rgns <- read_sf(rgns_json)
  can_gsl <- read_sf(can_gsl_url) %>%
    mutate(
      region = "CAN-GoStLawrence") %>% 
    select(region)
  rgns <- rbind(
    rgns %>% filter(region!="CAN-GoStLawrence"),
    can_gsl)
  
  write_sf(rgns, rgns_json, delete_dsn=T)
}
rgns <- read_sf(rgns_json)

rgns %>% 
  mutate(
    region = recode(
      region, 
      `USA_West`  = "USA-West",
      `USA_GoMex` = "USA-GoMex",
      `USA_East`  = "USA-East",
      `CAN_GoStLawrence` = "CAN-GoStLawrence")) %>% 
  select(rgn = region) %>% 
  write_sf(rgns_json, delete_dsn=T)
```

## Upload to BigQuery DB

```{r}
# vars
bq_tbl_rgns <- "benioff-ocean-initiative.whalesafe_v4.rgns"
update_rgns <- F # set to TRUE if you want to update the regions table

bq_ds_rgns  <- str_replace(bq_tbl_rgns, "([^.]+)\\.([^.]+)\\.([^.]+)", "\\1.\\2")
if (!bq_dataset_exists(bq_ds_rgns))
  bq_dataset_create(bq_ds_rgns)

if (!bq_table_exists(bq_tbl_rgns) | update_rgns){
  
  rgns <- read_sf(rgns_json)
  rgns_wkt <- rgns %>% 
    mutate(
      wkt = st_as_text(geometry)) %>% 
    st_drop_geometry()
  
  if (!bq_table_exists(bq_tbl_rgns)){
    bq_table_delete(bq_tbl_rgns)
  }
    
  # create the table schema
  bq_rgns <- bq_table_create(
    bq_tbl_rgns,
    rgns_wkt,
    friendly_name = "WhaleSafe regions",
    description   = "Created by:
        https://github.com/BenioffOceanInitiative/ws-sql/blob/main/load_regions.Rmd",
    labels = list(category = "spatial"))
  
  # upload the table contents
  bq_table_upload(bq_tbl_rgns, rgns_wkt)
  
  # create and update Geography column from well-known text (wkt)
  bq_dataset_query(
    bq_ds_rgns,
    glue(
      "ALTER TABLE {bq_tbl_rgns} ADD COLUMN IF NOT EXISTS geog GEOGRAPHY;
       UPDATE {bq_tbl_rgns} SET geog = ST_GEOGFROMTEXT(wkt) WHERE TRUE;
       ALTER TABLE {bq_tbl_rgns} DROP COLUMN IF EXISTS wkt"))
  # NOTE: UPDATE requires WHERE TRUE; try in console editor to see errors
}

rgns_bq <- bq_table_download(bq_tbl_rgns) %>% 
  st_as_sf(wkt = "geog", crs = 4326)
```

## DBI setup


```{r dbi}
bq_tbl_gfw <- "benioff-ocean-initiative.whalesafe_v4.gfw_daily_spireonly"
# bq_tbl_gfw <- "benioff-ocean-initiative.whalesafe_v4.gfw_daily_tmp"

bq_ds  <- str_replace(bq_tbl_gfw, "([^.]+)\\.([^.]+)\\.([^.]+)", "\\1.\\2")

sql_glue <- function(sql){
  readLines(here(sql)) %>% 
    paste(collapse = "\n") %>% 
    glue() # cat(sql)
}
```


## Create tables

Oddly the account `ships4whales@benioff-ocean-initiative.iam.gserviceaccount.com` used for non-interactive access to BigQuery doesn't seem to be able to create tables despite having the following roles in [IAM – IAM & Admin – Benioff Ocean Initi… – Google Cloud Platform](https://console.cloud.google.com/iam-admin/iam?referrer=search&authuser=1&project=benioff-ocean-initiative):

- BigQuery Admin
- BigQuery Data Editor
- BigQuery Job User
- Storage Object Admin

So I ran via Google Console as `benbest@ucsb.edu`.

Wierdly `ben@ecoquants.com`cannot create tables either:

```sql
CREATE TABLE IF NOT EXISTS `benioff-ocean-initiative.whalesafe_v4.gfw_daily_spireonly` (
  msgid STRING,
  ssvid STRING)
```

```
# Error running query
# IAM setPolicy failed for Dataset benioff-ocean-initiative:_scriptfc2436c39b5118cebb6b1551861bc436d98a5e24: One or more users named in the policy do not belong to a permitted customer.
```

```{r}
messages_scored_table                     <- "world-fishing-827.pipe_production_v20201001.messages_scored_"
research_satellite_timing_table           <- "world-fishing-827.gfw_research.pipe_v20201001_satellite_timing"
static_sunrise_dataset_and_table          <- "world-fishing-827.pipe_static.sunrise"
static_norad_to_receiver                  <- "world-fishing-827.pipe_static.norad_to_receiver_v20200127"
satellite_positions_one_second_resolution <- "world-fishing-827.satellite_positions_v20190208.satellite_positions_one_second_resolution_"

sql <- readLines(here("sql_v4/create_gfw-daily.sql")) %>%
  paste(collapse = "\n") %>%
  glue()

#dbExecute(con, sql)
# not working via ships4whales@benioff-ocean-initiative.iam.gserviceaccount.com
# so run in https://console.cloud.google.com/bigquery as benbest@ucsb.edu
cat(sql)
```


## Execute per region

```{r exec-rgns}
date <- Sys.Date() - 7

d_rgns <- dbGetQuery(con, "SELECT region, ST_Extent(geog) AS bbox FROM regions GROUP BY region")

#for (i in 1:nrow(d_rgns)){ # i = 2
for (i in 2:nrow(d_rgns)){ # i = 2
  d_rgn    <- d_rgns %>% slice(i)
  rgn      <- d_rgn$region
  rgn_bbox <- d_rgn$bbox[[1]]
  
  sql_glue("sql_v4/insert_gfw-daily_spire-only_ws-rgn.sql") %>% cat()
  #dbSendQuery(con, sql_glue("sql_v4/insert_gfw-daily_spire-only_ws-rgn.sql"))
  # Error in UseMethod("as_bq_table") : 
  #   no applicable method for 'as_bq_table' applied to an object of class "NULL"
  dbExecute(con, sql_glue("sql_v4/insert_gfw-daily_spire-only_ws-rgn.sql"))
}
```

