---
title: "bigrquery-test"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F)
```

## Connect to BigQuery

To run queries on BigQuery from RStudio, you'll need to:

1. Download this `json` file onto your machine (Important! This file MUST live outside of any Github repositories or publicly available spaces since it's a password and can be used to conscript paid services for evil doing!):

  - [Benioff Ocean Initiative-454f666d1896.json](https://drive.google.com/file/d/19_cCqCuNbJdEOxNNVwKYcTf8HpZDHunX/view?usp=sharing) - Note: you must be authorized to read this Google Drive folder.
  
2. Get your username by running `Sys.info()[["effective_user"]]` in the R Console and pasting path to directory where `Benioff Ocean Initiative-454f666d1896.json` was saved into chunk below next to your usernameme, eg `bbest = "/Volumes/GoogleDrive/My Drive/projects/whalesafe/data/gfw"`.

```{r}
if (!require(librarian)){
  install.packages("librarian")
  library(librarian)
}
shelf(
  bigrquery, connections, DBI, dplyr, here)

# ships4whales@benioff-ocean-initiative.iam.gserviceaccount.com
dir_auth_json <- switch(
  Sys.info()[["effective_user"]],
  calliesteffen = "/Volumes/GoogleDrive/My Drive/whalesafe/data/gfw",
  bbest         = "/Volumes/GoogleDrive/My Drive/projects/whalesafe/data/gfw",
  rachelrhodes  = "/Volumes/GoogleDrive/My Drive/projects/whalesafe/data/gfw/Benioff Ocean Initiative-454f666d1896.json",
  cdobbelaere   = "~/TBD.json")
auth_json <- file.path(dir_auth_json, "Benioff Ocean Initiative-454f666d1896.json")
stopifnot(file.exists(auth_json))

bigrquery::bq_auth(path = auth_json)

# con <- DBI::dbConnect(
#   bigrquery::bigquery(),
#   project = "benioff-ocean-initiative",
#   dataset = "whalesafe_v3",
#   billing = "benioff-ocean-initiative")
# con

con <- connections::connection_open(
  bigrquery::bigquery(),
  project = "benioff-ocean-initiative",
  dataset = "whalesafe_v3",
  billing = "benioff-ocean-initiative",
  use_legacy_sql = FALSE)

# connection_close(con)
```

## Working Queries on Benioff & GFW

```{r}
# querying Benioff
tb <- bq_project_query(
  x = "benioff-ocean-initiative",
  query = "SELECT * EXCEPT(linestring, point)
    FROM `benioff-ocean-initiative.whalesafe_v3.ais_segments`
    WHERE DATE(timestamp) > (CURRENT_DATE() - 7)
    LIMIT 10;")
# Running job 'benioff-ocean-initiative.job_m8HLodpfodohXd2cdbIdFtA3hxCy.US' [|]  4s
# Complete
# Billed: 22.02 MB

# querying GFW
tb <- bq_project_query(
  x = "benioff-ocean-initiative",
  query = "SELECT msgid, timestamp, seg_id, lat, lon FROM
    `world-fishing-827.pipe_production_v20201001.messages_scored_20210518`
    LIMIT 10;")
bq_table_download(tb)
```

## Test Connection

```{r}
# list projects
(projects <- bq_projects())
prj <- projects[[1]]

# list project datasets
bq_project_datasets(prj)

# list jobs
jobs <- try(bq_project_jobs(prj))
jobs[1:3]
```

```{r}
# query a public dataset
sql <- "SELECT year, month, day, weight_pounds FROM `publicdata.samples.natality` LIMIT 10"

tb <- try(bq_project_query(prj, sql))

if (!"try-error" %in% class(tb))
   try(bq_table_download(tb, max_results = 10))
```

## Common BigQuery errors surmounted

### `Cannot query ... without a filter`

```{sql connection=con, eval=F}
SELECT * FROM ais_segments LIMIT 10;
```

```
Error: Cannot query over table 'ais_data' without a filter over column(s) 'timestamp' that can be used for partition elimination [invalidQuery]
In addition: Warning message:
In class(obj) <- c("scalar", class(obj)) :
  Setting class(x) to multiple strings ("scalar", "SQL", ...); result will no longer be an S4 object
Failed to execute SQL chunk
```

### `Unknown type GEOGRAPHY`

```{sql connection=con, eval=F}
SELECT * FROM ais_segments 
WHERE DATE(timestamp) > (CURRENT_DATE() - 7)
LIMIT 10;
```

```
Running job 'benioff-ocean-initiative.job_QNlp_dzhVrQ38KoJgTf8hFxIZ-3f.US' [|]  1s
Complete
Billed: 13.63 MB
Downloading 10 rows in 1 pages.
Error in bq_parse_files(schema_path, page_paths, n = page_info$n_rows,  : 
  Unknown type GEOGRAPHY
In addition: Warning message:
In class(obj) <- c("scalar", class(obj)) :
  Setting class(x) to multiple strings ("scalar", "SQL", ...); result will no longer be an S4 object
Failed to execute SQL chunk
```

#### Getting Schema info on columns

```{sql connection=con}
SELECT * FROM whalesafe_v3.INFORMATION_SCHEMA.TABLES ORDER BY table_name;
```

```{sql connection=con}
SELECT
 -- * 
 -- EXCEPT(is_generated, generation_expression, is_stored, is_updatable)
 data_type, column_name, is_partitioning_column
FROM
 whalesafe_v3.INFORMATION_SCHEMA.COLUMNS
WHERE
 table_name="ais_segments"
ORDER BY
 data_type, column_name;
```

### Solutions: Use `EXCEPT()` to exclude geography columns, `WHERE` to add filter

```{sql connection=con}
SELECT * EXCEPT(linestring, point)           -- exclude geography columns
FROM ais_segments 
WHERE DATE(timestamp) > (CURRENT_DATE() - 7) -- filter by timestamp
ORDER BY timestamp DESC
LIMIT 10;
```


## Other 2

```{r, eval=F}
# get date
tb <- bq_project_query(
  x = "benioff-ocean-initiative",
  query = "SELECT CURRENT_DATE() as the_date;")
bq_table_download(tb)

# query ais_segments
sql <- "
  SELECT * EXCEPT(linestring, point)
  FROM ais_segments 
  WHERE DATE(timestamp) > (CURRENT_DATE() - 7)
  ORDER BY timestamp DESC
  LIMIT 10;"
# ds <- bq_dataset("benioff-ocean-initiative", "whalesafe_v3")
tb <- bq_dataset_query(
  x = "benioff-ocean-initiative.whalesafe_v3",
  query = sql,
  billing = "benioff-ocean-initiative")
bq_table_download(tb)

# run from text file
sql <- readLines(here("gfw/test.sql")) %>% 
  paste(collapse = "\n") 
cat(sql)
```

```{r, eval=F}
# sql <- "SELECT CURRENT_DATE() as the_date;"
tb <- bq_project_query(
  x = "benioff-ocean-initiative",
  query = sql,
  parameters=list(
    messages_scored_table = "world-fishing-827.pipe_production_v20201001.messages_scored_", 
    research_satellite_timing_table = "world-fishing-827.gfw_research.pipe_v20201001_satellite_timing"))
#bq_table_download(tb)
```

```
Query parameters cannot be used in place of table names at [22:3] [invalidQuery]
```

```{r, eval=F}
library(glue)

messages_scored_table = "world-fishing-827.pipe_production_v20201001.messages_scored_"
research_satellite_timing_table = "world-fishing-827.gfw_research.pipe_v20201001_satellite_timing"

sql <- readLines(here("gfw/test_glue.sql")) %>% 
  paste(collapse = "\n") %>% 
  glue(
    .open = "{{",
    .close = "}}")
cat(sql)

# sql <- "SELECT CURRENT_DATE() as the_date;"
tb <- bq_project_query(
  x = "benioff-ocean-initiative",
  query = sql)
#bq_table_download(tb)
```

```
x Not found: Table world-fishing-827:pipe_production_v20201001.messages_scored_ was not found in location US
```

```{r, eval=F}
library(glue)

messages_scored_table = "world-fishing-827.pipe_production_v20201001.messages_scored_*"
research_satellite_timing_table = "world-fishing-827.gfw_research.pipe_v20201001_satellite_timing"
mdate <- Sys.Date() - 2

sql <- readLines(here("gfw/test_glue2.sql")) %>% 
  paste(collapse = "\n") %>% 
  glue() # cat(sql)

tb <- bq_project_query(
  x = "benioff-ocean-initiative",
  query = sql)
# bq_table_download(tb)
```


## References

- Reference: [bigrquery.r-dbi.org](https://bigrquery.r-dbi.org)
- For non-interactive usage, using:
  - [ships4whales@benioff-ocean-initiative.iam.gserviceaccount.com](https://console.cloud.google.com/iam-admin/serviceaccounts/details/114569616080626900590?authuser=3&project=benioff-ocean-initiative)
- sidenote: alternate account
  - [whalesafe_table_updater – IAM & Admin – Benioff Ocean Initi… – Google Cloud Platform](https://console.cloud.google.com/iam-admin/serviceaccounts/details/108185723528190775192?authuser=3&project=benioff-ocean-initiative)
- Service account token, per [How to get your own API credentials • gargle](https://gargle.r-lib.org/articles/get-api-credentials.html#service-account-token)
  - From the Developers Console, in the target GCP Project, go to IAM & Admin > Service accounts
  - whalesafe_table_updater > KEYS menu > ADD KEY button
  - Downloaded [benioff-ocean-initiative-b208e85608c2.json](https://drive.google.com/open?id=1ClWXfMMVxufY4-_EPyOj2hHnC4dU3qtS&authuser=ben%40ecoquants.com&usp=drive_fs) into [gfw - Google Drive](https://drive.google.com/drive/u/3/folders/1crBGnOPGiKdWbtOLQhzgdJKA1ztZBzTM) and uploaded into server `/home/admin`
- [airflow - Is there a way to use dynamic dataset name in bigquery - Stack Overflow](https://stackoverflow.com/questions/60397307/is-there-a-way-to-use-dynamic-dataset-name-in-bigquery)
- [DB in RStudio: big-query](https://db.rstudio.com/databases/big-query/)
- [RStudio Connections Pane](https://db.rstudio.com/rstudio/connections/)
- [Using SQL in RStudio](https://irene.rbind.io/post/using-sql-in-rstudio/)

### Parameters

* [Running parameterized queries  |  BigQuery  |  Google Cloud](https://cloud.google.com/bigquery/docs/parameterized-queries)
* [Named parameters  |  BigQuery  |  Google Cloud](https://cloud.google.com/bigquery/docs/samples/bigquery-query-params-named)
* [sql - how to set named parameter on bigquery query - Stack Overflow](https://stackoverflow.com/questions/42628367/how-to-set-named-parameter-on-bigquery-query)
* [Query parameters in the BigQuery UI [35905569] - Visible to Public - Issue Tracker](https://issuetracker.google.com/issues/35905569?pli=1)
* [Run Queries Safely](https://db.rstudio.com/best-practices/run-queries-safely/)
* [Submit query to BigQuery — bq_query • bigrquery](https://bigrquery.r-dbi.org/reference/bq_query.html)
* [BigQuery jobs: perform a job — api-perform • bigrquery](https://bigrquery.r-dbi.org/reference/api-perform.html)
* [Explicitly define query parameters — bq_param • bigrquery](https://bigrquery.r-dbi.org/reference/bq_param.html)
* [S3 classes that reference remote BigQuery datasets, tables and jobs — bq_refs • bigrquery](https://bigrquery.r-dbi.org/reference/bq_refs.html)
* [Dynamic queries with BigQuery from R - Stack Overflow](https://stackoverflow.com/questions/51747814/dynamic-queries-with-bigquery-from-r)
