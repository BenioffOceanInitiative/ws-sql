---
title: "load_zones"
author: "Ben Best"
date: "11/18/2021"
output:
  html_document:
    #   "--shift-heading-level-by=-1"]
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
    # pandoc_args: [
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F)
```

```{r libraries}
librarian::shelf(
  dplyr, DT, glue, here, googlesheets4, here, htmltools, 
  lwgeom, mapview, purrr, readr, sf, stringr, tibble, tidyr,
  quiet = T)
source(here("scripts/db.R"))
```

```{r html-dependencies, include=FALSE}
# Init Step to make sure that the dependencies are loaded
tagList(datatable(cars))
mapview()
```

* [load `zones` spatially into db, including dates and other parameters (vessel, mandatory/voluntary) 路 Issue #8 路 BenioffOceanInitiative/ws-sql](https://github.com/BenioffOceanInitiative/ws-sql/issues/8)
  - nested under `rgns`: [Create and Load Regions `rgns` for hierarchical spatial analysis 路 Issue #7 路 BenioffOceanInitiative/ws-sql](https://github.com/BenioffOceanInitiative/ws-sql/issues/7)
  - [zones](https://docs.google.com/spreadsheets/d/1DnE1RY7exhRzc-e3kd8sX9HKRbjEvBHS4aZFXFLupeM/edit#gid=0) Google Sheet
  - `dir_shp`: [zones_shp - Google Drive](https://drive.google.com/drive/u/1/folders/1JRmhQEzRjoTUEsPkctUm4_x316D39E_9)
  

```{r paths-gsheet, results='asis'}
dir_shp    <- "/Volumes/GoogleDrive/.shortcut-targets-by-id/1SHlPwuO32zevQ6W9ZHb-CQLigiXRFeDY/AIS Ship Report Cards/Data/zones_shp"
rgns_json  <- here("data/ws-rgns.geojson")
zones_json <- here("data/ws-zones.geojson")
zones_csv  <- here("data/ws-zones.csv")
redo       <- FALSE


# [slow_zone_metadata - Google Sheets](https://docs.google.com/spreadsheets/d/1DnE1RY7exhRzc-e3kd8sX9HKRbjEvBHS4aZFXFLupeM/edit#gid=0)
zones_gsheetid <- "1DnE1RY7exhRzc-e3kd8sX9HKRbjEvBHS4aZFXFLupeM"
# shared with ships4whales@benioff-ocean-initiative.iam.gserviceaccount.com
# https://console.cloud.google.com/iam-admin/serviceaccounts/details/114569616080626900590;edit=true?previousPage=%2Fapis%2Fcredentials%3Fproject%3Dbenioff-ocean-initiative%26authuser%3D1&authuser=1&project=benioff-ocean-initiative
stopifnot(file.exists(auth_json)) # auth_json defined in db.R

gs4_auth(path = auth_json)
#sheet_names(zones_gsheetid) %>% paste(collapse = ", ")
# filtering_options, meta_regions, meta_zones, for_website

# rgns
# read_sf(rgns_json) %>% 
#   st_drop_geometry() %>% 
#   pull(rgn) %>% 
#   paste(collapse = ", ") %>% 
#   cat() # USA-West, USA-GoMex, USA-East, CAN-GoStLawrence

d_zones <- read_sheet(zones_gsheetid, "zones_spatial") %>% 
  # mutate(
  #   start_date = as.character(start_date),
  #   end_date   = as.character(end_date)) %>% 
  arrange(rgn, zone) 
# View(d_zones)

hdr <- function(x, h="###"){
  cat(glue("\n\n{h} {x}\n\n"))
}
```

```{r}
if (file.exists(zones_json)){
  zones <- sf::read_sf(zones_json)
  mapview::mapview(zones)
} 
```


# Zones

Source: [slow_zone_metadata - Google Sheets](https://docs.google.com/spreadsheets/d/1DnE1RY7exhRzc-e3kd8sX9HKRbjEvBHS4aZFXFLupeM/edit#gid=0)

## MISSING shapefile

```{r tbl-zones, results='asis'}
tbl <- d_zones %>% 
  filter(is.na(path_shp)) %>% 
  select(-note, -path_shp, -shp_filter) %>% 
  datatable()

print(tagList(tbl))
```

```{r make-zones-geojson, eval = F}
# ensure each zone is uniquely named
stopifnot(any(!duplicated(d_zones$zone)))

get_sf <- function(path_shp, shp_filter){
  # path_shp = zones_sf$path_shp[1]; f = zones_sf$shp_filter[1]
  # path_shp = "{dir_shp}/United States/SF_VSR/vsr_sf_2022/sf_vsr_2022.shp"; shp_filter=NA
  message(glue("path_shp:{path_shp}; shp_filter:{shp_filter}"))
  
  # if (f == 'Restr_Area == "Mid-Atl Block Island Sound"')
  #browser()
  f_expr <- rlang::parse_expr(shp_filter)
  
  d <- read_sf(glue(path_shp))
  
  if (is.na(st_crs(d)))
    st_crs(d) <- 4326

  if (!is.na(f_expr))
    d <- filter(d, !!f_expr)
    
  # if (shp_filter == 'layer %in% c("northern_static", "southern_static")')
  #   browser()
  
  if (nrow(d) > 1){
    geom <- d %>%
      st_union()
  } else {
    geom <- d %>% 
      pull(geometry)
  }
  
  geom %>% 
    st_transform(4326)
}

# create geojson
zones_sf <- d_zones %>% 
  filter(!is.na(path_shp)) %>% 
  # slice(4:13) %>% 
  mutate(
    geometry = map2(path_shp, shp_filter, get_sf)) %>% 
  unnest(geometry) %>% 
  st_as_sf()
  
# ensure each zone is uniquely named
stopifnot(any(!duplicated(zones_sf$zone)))

write_sf(zones_sf, zones_json, delete_dsn=T)
zones_sf %>% 
  st_drop_geometry() %>% 
  write_csv(zones_csv)
```

```{r upload-zones-to-bq, eval = F}
# upload zones without missing shapefile into bigquery
bq_tbl_zones <- "benioff-ocean-initiative.whalesafe_v4.zones"
bq_ds        <- "benioff-ocean-initiative.whalesafe_v4"

source(here("scripts/db.R"))

zones <- read_sf(zones_json)

stopifnot(st_is_valid(zones)) # lwgeom::lwgeom_make_valid()
# Query error: ST_GeogFromText failed: Invalid polygon loop: Edge 55 crosses edge 57 at [2:1]

zones_wkt <- zones %>% 
  mutate(
    wkt = st_as_text(geometry)) %>% 
  st_drop_geometry()

if (bq_table_exists(bq_tbl_zones)){
  bq_table_delete(bq_tbl_zones)
}

# create the table schema
bq_zones <- bq_table_create(
  bq_tbl_zones,
  zones_wkt,
  friendly_name = "WhaleSafe zones",
  description   = "Created by:
      https://github.com/BenioffOceanInitiative/ws-sql/blob/main/load_zones.Rmd",
  labels = list(category = "spatial"))

# upload the table contents
bq_table_upload(bq_tbl_zones, zones_wkt)

# create and update Geography column from well-known text (wkt)
dbExecute(con, glue(
  "ALTER TABLE {bq_tbl_zones} ADD COLUMN IF NOT EXISTS geog GEOGRAPHY;
   UPDATE {bq_tbl_zones} SET geog = ST_GEOGFROMTEXT(wkt, make_valid => TRUE) WHERE TRUE;
   ALTER TABLE {bq_tbl_zones} DROP COLUMN IF EXISTS wkt;"))
# ERROR in BigQuery SQL Workspace
#   Query error: ST_GeogFromText failed: Invalid polygon loop: Edge 55 crosses edge 57 at [2:1]
#   SOLUTION: ST_GEOGFROMTEXT(wkt, make_valid => TRUE)
```

```{r show-map-table-per-zone, results='asis'}
for (r in unique(d_zones$rgn)){ # r = "USA-West"
  
  hdr(r, "##")
  
  zones_r <- d_zones %>% 
    filter(
      rgn == r,
      !is.na(path_shp)) %>% 
    pull(zone)
  
  for (z in zones_r){ # z = "SF-VSR"; z = "SE-RwhaleNursery"
    
    d_z <- d_zones %>% 
      filter(zone == z)
    d_z %>% select(path_shp)
    
    if (is.na(d_z$path_shp)){
      hdr(glue("{z}: NO `path_shp`"))
      next
    } 
    
    hdr(z)
  
    path_shp   <- glue(d_z$path_shp) # expect "{dir_shp}/.."
    shp_filter <- d_z$shp_filter
    
    s_z <- read_sf(path_shp)
    
    if (!is.na(shp_filter))
      s_z <- s_z %>% filter(eval(parse(text = shp_filter)))
    
    hdr("map", "####")
    map <- mapview(s_z)
    print(tagList(map@map))
    
    hdr("table", "####")
    tbl <- s_z %>% 
      st_drop_geometry() %>% 
      datatable()
    print(tagList(tbl))
  }
}
```

# Shapefiles

```{r, results='asis'}
stopifnot(fs::dir_exists(dir_shp))
d_shps <- tibble(
  shp = list.files(dir_shp, ".*\\.shp$", recursive = T)) %>% 
  mutate(
    rgn = str_replace(shp, "(.*?)/.*", "\\1"))

rgns <- unique(d_shps$rgn)

for (rgn in rgns){ # rgn = rgns[1]

  hdr(rgn, "##")
  
  d_shps_rgn <- filter(d_shps, rgn == !!rgn)
  
  for (shp in d_shps_rgn$shp){ # shp = d_shps_rgn$shp
    
    path_shp <- glue("{dir_shp}/{shp}")
    
    hdr(shp, "###")
    
    s_z <- read_sf(path_shp)
    
    hdr("map", "####")
    
    map <- mapview(s_z)
    
    print(tagList(map@map))
    
    hdr("table", "####")
    tbl <- s_z %>% 
      st_drop_geometry() %>% 
      datatable()
    print(tagList(tbl))
  }
}
```

