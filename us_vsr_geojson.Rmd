---
title: "us_vsr_geojson"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## US VSR (vessel strike restrictions) zone data scraper

See [US VSR zone data scraper · Issue #2 · BenioffOceanInitiative/ws-sql](https://github.com/BenioffOceanInitiative/ws-sql/issues/2)

```{r warning=F}
# TODO: 
# - injecting into BigQuery
# - setup as a cron job service


# libraries ---
if (!require(librarian)){
  install.packages("librarian")
  library(librarian)
}
shelf(
  dplyr,
  glue,
  here,
  purrr,
  sf,
  tidyr,
  xml2)

# variables ----
url <- "https://apps-nefsc.fisheries.noaa.gov/cgi-bin/mammalmaps/xmlgenDMA.pl"
geo <- here("data/usa_nefsc_dyn-mgt-areas.geojson")

# ingest ----
x   <- read_xml(url) # alternative method of reading 

nodes <- xml_find_all(x, "//dma")

d <- nodes %>% 
  xml_attrs() %>% 
  map_df(~as.list(.)) %>% 
  mutate(
    waypoints = map(id, function(id){ # id = d$id[1]
      w <- nodes %>% 
        xml_find_all(glue("//dma[@id='{id}']/child::node()")) %>% 
        xml_attrs() %>%
        map_df(~as.list(.))
      
      w %>% 
        # duplicate first lat/lon values for creating polygons
        bind_rows(
          w %>% slice(1))} ))

p <- d %>% 
  unnest(waypoints) %>% 
  select(id, lon, lat) %>% 
  group_by(id) %>% 
  st_as_sf(coords = c("lat", "lon"), crs = 4326) %>% 
  summarize(sfc_geometry = st_combine(geometry)) %>% 
  st_cast("POLYGON") %>% 
  left_join(
    d %>% 
      select(-waypoints),
    by = "id")

st_write(p, geo)
```

